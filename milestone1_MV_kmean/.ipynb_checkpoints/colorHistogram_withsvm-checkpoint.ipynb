{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23205328-4f79-47a4-8a5f-2d48770bf7f9",
   "metadata": {},
   "source": [
    "## import libarary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9cf1aa-e0f6-4a3e-9b43-c92551bceb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras import datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plot\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c93c9-a6a9-48ff-9dc7-1de610131804",
   "metadata": {},
   "source": [
    "##  Load the Caltech101 dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87a276-da16-4af0-84a9-0f52c038cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Caltech101 dataset\n",
    "dataset, info = tfds.load('caltech101', with_info=True, as_supervised=True)\n",
    "\n",
    "# Split the dataset into training and testing\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f081c4-c2b2-4030-ba79-008792c57820",
   "metadata": {},
   "source": [
    "## Convert train and test data into numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad64d47-e96c-495c-831b-001038dbc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, image_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image, label in data:\n",
    "        # Resize image to the desired shape\n",
    "        image_resized = cv2.resize(image.numpy(), image_size)\n",
    "        images.append(image_resized)\n",
    "        labels.append(label.numpy())\n",
    "        \n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe0f14-d533-4943-8a50-d6cd288fe569",
   "metadata": {},
   "source": [
    "## Load and preprocess training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7eff7b-bcaf-47bf-8a0a-7bd78c4ee919",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = process_data(train_data)\n",
    "X_test, y_test = process_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad95510-ad95-4e86-84ac-ecb1f061df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e812c05-9f51-4e27-ba8d-47287fc92767",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in X_train])\n",
    "X_test_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1c447-6ba2-42be-8903-c96c95b65a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_histogram_equalization(images):\n",
    "    \"\"\"\n",
    "    Applies histogram equalization to a list of grayscale images.\n",
    "    \n",
    "    Args:\n",
    "        images (list or ndarray): A list or array of grayscale images.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of enhanced grayscale images after histogram equalization.\n",
    "    \"\"\"\n",
    "    enhanced_images = []\n",
    "    for img in images:\n",
    "        # Apply Histogram Equalization to the grayscale image\n",
    "        equalized_img = cv2.equalizeHist(img)\n",
    "        enhanced_images.append(equalized_img)\n",
    "    \n",
    "    return enhanced_images\n",
    "\n",
    "# Apply histogram equalization to the training and testing grayscale datasets\n",
    "enhanced_Trainimagesg = apply_histogram_equalization(X_train_gray)\n",
    "enhanced_Testimagesg = apply_histogram_equalization(X_test_gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2a3529-2f1c-4278-9715-d2896a606361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_histogram_equalization(images):\n",
    "    \"\"\"\n",
    "    Apply histogram equalization to each channel of color images.\n",
    "    \n",
    "    Args:\n",
    "        images (list or ndarray): List or array of color images.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of enhanced color images with equalized histograms.\n",
    "    \"\"\"\n",
    "    equalized_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        # Split the image into its RGB channels\n",
    "        b, g, r = cv2.split(image)\n",
    "        \n",
    "        # Apply histogram equalization to each channel\n",
    "        b = cv2.equalizeHist(b)\n",
    "        g = cv2.equalizeHist(g)\n",
    "        r = cv2.equalizeHist(r)\n",
    "        \n",
    "        # Merge the equalized channels back\n",
    "        equalized_image = cv2.merge((b, g, r))\n",
    "        equalized_images.append(equalized_image)\n",
    "    \n",
    "    return equalized_images\n",
    "\n",
    "# Apply histogram equalization to the training and testing color datasets\n",
    "enhanced_Trainimages = apply_color_histogram_equalization(X_train)\n",
    "enhanced_Testimages = apply_color_histogram_equalization(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abba462-0731-4cf5-8b51-d7a6de054e14",
   "metadata": {},
   "source": [
    "## Define Color Histogram parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e31cb34-baf2-4c00-a3e4-fb093bbe21a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_histogram(images, image_size=(128, 128), bins=32):\n",
    "    colors = (\"blue\", \"green\", \"red\")\n",
    "    features = []\n",
    "\n",
    "    for image in images:\n",
    "        # Convert the image to BGR format if it's in RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image = cv2.resize(image, image_size)  # Ensure consistent size\n",
    "        \n",
    "        image_histograms = []\n",
    "\n",
    "        # Optional: Divide the image into 4 regions\n",
    "        h, w, _ = image.shape\n",
    "        regions = [\n",
    "            image[0:h//2, 0:w//2],  # Top-left\n",
    "            image[0:h//2, w//2:w],  # Top-right\n",
    "            image[h//2:h, 0:w//2],  # Bottom-left\n",
    "            image[h//2:h, w//2:w],  # Bottom-right\n",
    "        ]\n",
    "\n",
    "        for region in regions:\n",
    "            # Loop over each channel (blue, green, red)\n",
    "            for j, color in enumerate(colors):\n",
    "                # Calculate the histogram for each channel\n",
    "                hist = cv2.calcHist([region], [j], None, [bins], [0, 256])\n",
    "                hist = cv2.normalize(hist, hist).flatten()  # Normalize and flatten\n",
    "                image_histograms.extend(hist)\n",
    "\n",
    "        # Append the concatenated histograms for this image to the feature list\n",
    "        features.append(image_histograms)\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9911a5-7e54-414d-adf4-5082661d0d0a",
   "metadata": {},
   "source": [
    "## Convert the list of features into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97217ae3-8465-4f5f-b8ad-2c429a7cf407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate color histogram features\n",
    "features_train = color_histogram(enhanced_Trainimages)\n",
    "features_test = color_histogram(enhanced_Testimages)\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7610de-8916-456e-9400-b6abae0bc8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lbp_histogram(image, radius=1, n_points=8):\n",
    "    # Compute the LBP image using skimage's local_binary_pattern\n",
    "    lbp_image = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "    \n",
    "    # Compute the histogram of the LBP image\n",
    "    lbp_hist, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, 257), range=(0, 256))\n",
    "    \n",
    "    # Normalize the histogram\n",
    "    lbp_hist = lbp_hist.astype(float)\n",
    "    lbp_hist /= lbp_hist.sum()  # Normalize the histogram to make it a probability distribution\n",
    "    \n",
    "    return lbp_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281daf1b-fdba-41d0-be68-90053939f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LBP\n",
    "X_train_lbp = np.array([compute_lbp_histogram(img) for img in enhanced_Trainimagesg])\n",
    "X_test_lbp = np.array([compute_lbp_histogram(img) for img in enhanced_Testimagesg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc06105d-278d-4847-bf41-0b370f279d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate features\n",
    "combined_features_train = np.hstack((features_train, X_train_lbp))\n",
    "combined_features_test = np.hstack((features_test, X_test_lbp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ab352-4e0e-45f2-8e78-8659975e0ac7",
   "metadata": {},
   "source": [
    "## Training the SVM model on the Training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a8aed4-cb53-4d10-a283-5c6d25860ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(kernel='linear', random_state=0)\n",
    "classifier.fit(combined_features_train, y_train.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4dd57e-55d9-4040-987c-0d2059ebd966",
   "metadata": {},
   "source": [
    "## Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51799ae1-068c-4c98-8861-1b2c3b705d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(combined_features_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca59906-d6b1-4701-9f5e-588a23bbfb72",
   "metadata": {},
   "source": [
    "## Evaluate the classifier's performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672e7ab-c6f5-42dc-b54c-7d2450247930",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test.flatten(), y_pred)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd3834-40ce-4160-9d2b-8b45bf942b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
