{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23205328-4f79-47a4-8a5f-2d48770bf7f9",
   "metadata": {},
   "source": [
    "## import libarary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e9cf1aa-e0f6-4a3e-9b43-c92551bceb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras import datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plot\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c93c9-a6a9-48ff-9dc7-1de610131804",
   "metadata": {},
   "source": [
    "##  Load the Caltech101 dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f87a276-da16-4af0-84a9-0f52c038cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Caltech101 dataset\n",
    "dataset, info = tfds.load('caltech101', with_info=True, as_supervised=True)\n",
    "\n",
    "# Split the dataset into training and testing\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f081c4-c2b2-4030-ba79-008792c57820",
   "metadata": {},
   "source": [
    "## Convert train and test data into numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad64d47-e96c-495c-831b-001038dbc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, image_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image, label in data:\n",
    "        # Resize image to the desired shape\n",
    "        image_resized = cv2.resize(image.numpy(), image_size)\n",
    "        images.append(image_resized)\n",
    "        labels.append(label.numpy())\n",
    "        \n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe0f14-d533-4943-8a50-d6cd288fe569",
   "metadata": {},
   "source": [
    "## Load and preprocess training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b7eff7b-bcaf-47bf-8a0a-7bd78c4ee919",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = process_data(train_data)\n",
    "X_test, y_test = process_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fad95510-ad95-4e86-84ac-ecb1f061df3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3059, 128, 128, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e812c05-9f51-4e27-ba8d-47287fc92767",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in X_train])\n",
    "X_test_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f1c447-6ba2-42be-8903-c96c95b65a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_histogram_equalization(images):\n",
    "    \"\"\"\n",
    "    Applies histogram equalization to a list of grayscale images.\n",
    "    \n",
    "    Args:\n",
    "        images (list or ndarray): A list or array of grayscale images.\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of enhanced grayscale images after histogram equalization.\n",
    "    \"\"\"\n",
    "    enhanced_images = []\n",
    "    for img in images:\n",
    "        # Apply Histogram Equalization to the grayscale image\n",
    "        equalized_img = cv2.equalizeHist(img)\n",
    "        enhanced_images.append(equalized_img)\n",
    "    \n",
    "    return enhanced_images\n",
    "\n",
    "# Apply histogram equalization to the training and testing grayscale datasets\n",
    "enhanced_Trainimagesg = apply_histogram_equalization(X_train_gray)\n",
    "enhanced_Testimagesg = apply_histogram_equalization(X_test_gray)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c2a3529-2f1c-4278-9715-d2896a606361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_histogram_equalization(images):\n",
    "    \"\"\"\n",
    "    Apply histogram equalization to each channel of color images.\n",
    "    \n",
    "    Args:\n",
    "        images (list or ndarray): List or array of color images.\n",
    "    \n",
    "    Returns:\n",
    "        list: List of enhanced color images with equalized histograms.\n",
    "    \"\"\"\n",
    "    equalized_images = []\n",
    "    \n",
    "    for image in images:\n",
    "        # Split the image into its RGB channels\n",
    "        b, g, r = cv2.split(image)\n",
    "        \n",
    "        # Apply histogram equalization to each channel\n",
    "        b = cv2.equalizeHist(b)\n",
    "        g = cv2.equalizeHist(g)\n",
    "        r = cv2.equalizeHist(r)\n",
    "        \n",
    "        # Merge the equalized channels back\n",
    "        equalized_image = cv2.merge((b, g, r))\n",
    "        equalized_images.append(equalized_image)\n",
    "    \n",
    "    return equalized_images\n",
    "\n",
    "# Apply histogram equalization to the training and testing color datasets\n",
    "enhanced_Trainimages = apply_color_histogram_equalization(X_train)\n",
    "enhanced_Testimages = apply_color_histogram_equalization(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abba462-0731-4cf5-8b51-d7a6de054e14",
   "metadata": {},
   "source": [
    "## Define Color Histogram parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e31cb34-baf2-4c00-a3e4-fb093bbe21a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_histogram(images, image_size=(128, 128), bins=32):\n",
    "    colors = (\"blue\", \"green\", \"red\")\n",
    "    features = []\n",
    "\n",
    "    for image in images:\n",
    "        # Convert the image to BGR format if it's in RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        image = cv2.resize(image, image_size)  # Ensure consistent size\n",
    "        \n",
    "        image_histograms = []\n",
    "\n",
    "        # Optional: Divide the image into 4 regions\n",
    "        h, w, _ = image.shape\n",
    "        regions = [\n",
    "            image[0:h//2, 0:w//2],  # Top-left\n",
    "            image[0:h//2, w//2:w],  # Top-right\n",
    "            image[h//2:h, 0:w//2],  # Bottom-left\n",
    "            image[h//2:h, w//2:w],  # Bottom-right\n",
    "        ]\n",
    "\n",
    "        for region in regions:\n",
    "            # Loop over each channel (blue, green, red)\n",
    "            for j, color in enumerate(colors):\n",
    "                # Calculate the histogram for each channel\n",
    "                hist = cv2.calcHist([region], [j], None, [bins], [0, 256])\n",
    "                hist = cv2.normalize(hist, hist).flatten()  # Normalize and flatten\n",
    "                image_histograms.extend(hist)\n",
    "\n",
    "        # Append the concatenated histograms for this image to the feature list\n",
    "        features.append(image_histograms)\n",
    "\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9911a5-7e54-414d-adf4-5082661d0d0a",
   "metadata": {},
   "source": [
    "## Convert the list of features into numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97217ae3-8465-4f5f-b8ad-2c429a7cf407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3059, 384)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate color histogram features\n",
    "features_train = color_histogram(enhanced_Trainimages)\n",
    "features_test = color_histogram(enhanced_Testimages)\n",
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be7610de-8916-456e-9400-b6abae0bc8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lbp_histogram(image, radius=1, n_points=8):\n",
    "    # Compute the LBP image using skimage's local_binary_pattern\n",
    "    lbp_image = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "    \n",
    "    # Compute the histogram of the LBP image\n",
    "    lbp_hist, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, 257), range=(0, 256))\n",
    "    \n",
    "    # Normalize the histogram\n",
    "    lbp_hist = lbp_hist.astype(float)\n",
    "    lbp_hist /= lbp_hist.sum()  # Normalize the histogram to make it a probability distribution\n",
    "    \n",
    "    return lbp_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "281daf1b-fdba-41d0-be68-90053939f197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LBP\n",
    "X_train_lbp = np.array([compute_lbp_histogram(img) for img in enhanced_Trainimagesg])\n",
    "X_test_lbp = np.array([compute_lbp_histogram(img) for img in enhanced_Testimagesg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc06105d-278d-4847-bf41-0b370f279d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate features\n",
    "combined_features_train = np.hstack((features_train, X_train_lbp))\n",
    "combined_features_test = np.hstack((features_test, X_test_lbp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ab352-4e0e-45f2-8e78-8659975e0ac7",
   "metadata": {},
   "source": [
    "## Training the SVM model on the Training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59a8aed4-cb53-4d10-a283-5c6d25860ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1-x2)**2))\n",
    "\n",
    "class KMeans:\n",
    "\n",
    "    def __init__(self, K=5, max_iters=100, plot_steps=False):\n",
    "        self.K = K\n",
    "        self.max_iters = max_iters\n",
    "        self.plot_steps = plot_steps\n",
    "\n",
    "        # list of sample indices for each cluster\n",
    "        self.clusters = [[] for _ in range(self.K)]\n",
    "\n",
    "        # the centers (mean vector) for each cluster\n",
    "        self.centroids = []\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.X = X\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "\n",
    "        # initialize centroids randomly\n",
    "        random_sample_idxs = np.random.choice(self.n_samples, self.K, replace=False)\n",
    "        self.centroids = [self.X[idx] for idx in random_sample_idxs]\n",
    "\n",
    "        # optimize clusters\n",
    "        for _ in range(self.max_iters):\n",
    "            # assign samples to closest centroids (create clusters)\n",
    "            self.clusters = self._create_clusters(self.centroids)\n",
    "\n",
    "            if self.plot_steps:\n",
    "                self.plot()\n",
    "\n",
    "            # calculate new centroids from the clusters\n",
    "            centroids_old = self.centroids\n",
    "            self.centroids = self._get_centroids(self.clusters)\n",
    "\n",
    "            if self._is_converged(centroids_old, self.centroids):\n",
    "                break\n",
    "\n",
    "            if self.plot_steps:\n",
    "                self.plot()\n",
    "\n",
    "        # classify samples as the index of their clusters\n",
    "        return self._get_cluster_labels(self.clusters)\n",
    "\n",
    "    def _get_cluster_labels(self, clusters):\n",
    "        labels = np.empty(self.n_samples)\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            for sample_idx in cluster:\n",
    "                labels[sample_idx] = cluster_idx\n",
    "        return labels\n",
    "\n",
    "    def _create_clusters(self, centroids):\n",
    "        clusters = [[] for _ in range(self.K)]\n",
    "        for idx, sample in enumerate(self.X):\n",
    "            centroid_idx = self._closest_centroid(sample, centroids)\n",
    "            clusters[centroid_idx].append(idx)\n",
    "        return clusters\n",
    "\n",
    "    def _closest_centroid(self, sample, centroids):\n",
    "        distances = [euclidean_distance(sample, point) for point in centroids]\n",
    "        closest_idx = np.argmin(distances)\n",
    "        return closest_idx\n",
    "\n",
    "    def _get_centroids(self, clusters):\n",
    "        centroids = np.zeros((self.K, self.n_features))\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            if len(cluster) == 0:\n",
    "                # handle empty clusters by reinitializing with a random point\n",
    "                centroids[cluster_idx] = self.X[np.random.choice(self.n_samples)]\n",
    "            else:\n",
    "                cluster_mean = np.mean(self.X[cluster], axis=0)\n",
    "                centroids[cluster_idx] = cluster_mean\n",
    "        return centroids\n",
    "\n",
    "    def _is_converged(self, centroids_old, centroids, tol=1e-4):\n",
    "        distances = [euclidean_distance(centroids_old[i], centroids[i]) for i in range(self.K)]\n",
    "        return sum(distances) < tol\n",
    "\n",
    "    def plot(self):\n",
    "        self.plot_clusters_2D()\n",
    "\n",
    "    def plot_clusters_2D(self):\n",
    "        pca = PCA(n_components=2)\n",
    "        reduced_data = pca.fit_transform(self.X)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        # Plot each cluster\n",
    "        for i, cluster in enumerate(self.clusters):\n",
    "            points = reduced_data[cluster]\n",
    "            ax.scatter(points[:, 0], points[:, 1], label=f\"Cluster {i}\")\n",
    "\n",
    "        # Plot the centroids (in the 2D PCA space)\n",
    "        centroids_2d = pca.transform(self.centroids)\n",
    "        ax.scatter(centroids_2d[:, 0], centroids_2d[:, 1], marker=\"x\", color=\"black\", linewidth=2, s=100)\n",
    "\n",
    "        ax.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13de2ca9-4e71-4cb7-a859-8b94b3ba3528",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_lbp = np.vstack((combined_features_train, combined_features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3895e7c3-5ab7-4073-bcd0-8b2d1cfb9601",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_y = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3731166-3bd8-4973-83ba-e49b8deb5350",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = len(np.unique(combined_y))\n",
    "k = KMeans(K=clusters, max_iters=150, plot_steps=False)\n",
    "y_pred = k.predict(combined_lbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4dd57e-55d9-4040-987c-0d2059ebd966",
   "metadata": {},
   "source": [
    "## Make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51799ae1-068c-4c98-8861-1b2c3b705d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_y = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca59906-d6b1-4701-9f5e-588a23bbfb72",
   "metadata": {},
   "source": [
    "## Evaluate the classifier's performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9672e7ab-c6f5-42dc-b54c-7d2450247930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8748906386701663\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(combined_y.flatten(), y_pred)\n",
    "print(\"Accuracy: \", accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd3834-40ce-4160-9d2b-8b45bf942b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
