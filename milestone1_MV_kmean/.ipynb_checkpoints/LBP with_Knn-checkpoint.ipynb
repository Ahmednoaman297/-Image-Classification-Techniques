{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23205328-4f79-47a4-8a5f-2d48770bf7f9",
   "metadata": {},
   "source": [
    "## import libarary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7e9cf1aa-e0f6-4a3e-9b43-c92551bceb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras import datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plot\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c93c9-a6a9-48ff-9dc7-1de610131804",
   "metadata": {},
   "source": [
    "##  Load the Caltech101 dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6f87a276-da16-4af0-84a9-0f52c038cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Caltech101 dataset\n",
    "dataset, info = tfds.load('caltech101', with_info=True, as_supervised=True)\n",
    "\n",
    "# Split the dataset into training and testing\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f081c4-c2b2-4030-ba79-008792c57820",
   "metadata": {},
   "source": [
    "## Convert train and test data into numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aad64d47-e96c-495c-831b-001038dbc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, image_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image, label in data:\n",
    "        # Resize image to the desired shape\n",
    "        image_resized = cv2.resize(image.numpy(), image_size)\n",
    "        images.append(image_resized)\n",
    "        labels.append(label.numpy())\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe0f14-d533-4943-8a50-d6cd288fe569",
   "metadata": {},
   "source": [
    "## Load and preprocess training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7b7eff7b-bcaf-47bf-8a0a-7bd78c4ee919",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = process_data(train_data)\n",
    "X_test, y_test = process_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fad95510-ad95-4e86-84ac-ecb1f061df3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3059, 128, 128, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b04e1-940f-4748-a4fa-0c88173e9608",
   "metadata": {},
   "source": [
    "## Convert images to grayscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "89b70455-1327-4574-ab54-9e1b9f20a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in X_train])\n",
    "X_test_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a77d39ae-0654-454a-9689-c418fea83704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3059, 128, 128)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_gray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63e6856-bc39-4cc7-a7ee-c8dda25e1b7c",
   "metadata": {},
   "source": [
    "## Function to compute LBP histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bd25b5e6-a89f-4b75-8685-757fb8c95670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lbp_histogram(image, radius=1, n_points=8):\n",
    "    # Compute the LBP image using skimage's local_binary_pattern\n",
    "    lbp_image = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "    \n",
    "    # Compute the histogram of the LBP image\n",
    "    lbp_hist, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, 257), range=(0, 256))\n",
    "    \n",
    "    # Normalize the histogram\n",
    "    lbp_hist = lbp_hist.astype(float)\n",
    "    lbp_hist /= lbp_hist.sum()  # Normalize the histogram to make it a probability distribution\n",
    "    \n",
    "    return lbp_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abba462-0731-4cf5-8b51-d7a6de054e14",
   "metadata": {},
   "source": [
    "## Now apply LBP on each grayscale image to get the histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d019f2a3-8bf4-4ecb-986b-729c416b8d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3059, 256)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lbp = np.array([compute_lbp_histogram(img) for img in X_train_gray])\n",
    "X_test_lbp = np.array([compute_lbp_histogram(img) for img in X_test_gray])\n",
    "X_train_lbp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e7bd0c03-c7ec-4f04-a3e8-4874c8face06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6085, 256)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_lbp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ab352-4e0e-45f2-8e78-8659975e0ac7",
   "metadata": {},
   "source": [
    "## Training the Kmean model on the Training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "59a8aed4-cb53-4d10-a283-5c6d25860ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    distance = np.sqrt(np.sum((x1-x2)**2))\n",
    "    return distance\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3): #we make default 3 the votes might be 2:1, ensuring a clear winner smaller than will be no winner or overfitting\n",
    "        self.k = k\n",
    "\n",
    "    def fit(self, X, y): #fit means stores our trainnig set\n",
    "        self.X_train = X    \n",
    "        self.y_train = y\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # compute the distance\n",
    "        distances = [euclidean_distance(x, x_train) for x_train in self.X_train] #x is the test set from xtrain to last value in x_train \n",
    "    \n",
    "        # get the closest k\n",
    "        k_indices_feature = np.argsort(distances)[:self.k] ## sorting ascending order to find the nearest point and determine which class belongs\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices_feature]\n",
    "\n",
    "        # majority voye\n",
    "        most_common = Counter(k_nearest_labels).most_common()  ## to count the occurrences of each element in an iterable (like a list).\n",
    "        return most_common[0][0]  ##first element in first label\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(x) for x in X]\n",
    "        return predictions\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e58863a6-9190-46f7-bdc3-346a7918f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNN(k=9)\n",
    "classifier.fit(X_train_lbp, y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f96aa02d-21d3-4249-96bd-7c53036eedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test_lbp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca59906-d6b1-4701-9f5e-588a23bbfb72",
   "metadata": {},
   "source": [
    "## Evaluate the classifier's performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9672e7ab-c6f5-42dc-b54c-7d2450247930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  18.405916187345934\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test.flatten(), y_pred)\n",
    "print(\"Accuracy: \", accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9463f-5107-4acd-92bb-6b77148d1d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
