{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23205328-4f79-47a4-8a5f-2d48770bf7f9",
   "metadata": {},
   "source": [
    "## import libarary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7e9cf1aa-e0f6-4a3e-9b43-c92551bceb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras import datasets\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plot\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c93c9-a6a9-48ff-9dc7-1de610131804",
   "metadata": {},
   "source": [
    "##  Load the Caltech101 dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6f87a276-da16-4af0-84a9-0f52c038cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Caltech101 dataset\n",
    "dataset, info = tfds.load('caltech101', with_info=True, as_supervised=True)\n",
    "\n",
    "# Split the dataset into training and testing\n",
    "train_data = dataset['train']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f081c4-c2b2-4030-ba79-008792c57820",
   "metadata": {},
   "source": [
    "## Convert train and test data into numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aad64d47-e96c-495c-831b-001038dbc7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, image_size=(128, 128)):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image, label in data:\n",
    "        # Resize image to the desired shape\n",
    "        image_resized = cv2.resize(image.numpy(), image_size)\n",
    "        images.append(image_resized)\n",
    "        labels.append(label.numpy())\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe0f14-d533-4943-8a50-d6cd288fe569",
   "metadata": {},
   "source": [
    "## Load and preprocess training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7b7eff7b-bcaf-47bf-8a0a-7bd78c4ee919",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = process_data(train_data)\n",
    "X_test, y_test = process_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fad95510-ad95-4e86-84ac-ecb1f061df3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3059, 128, 128, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9b04e1-940f-4748-a4fa-0c88173e9608",
   "metadata": {},
   "source": [
    "## Convert images to grayscale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "89b70455-1327-4574-ab54-9e1b9f20a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in X_train])\n",
    "X_test_gray = np.array([cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a77d39ae-0654-454a-9689-c418fea83704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3059, 128, 128)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_gray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63e6856-bc39-4cc7-a7ee-c8dda25e1b7c",
   "metadata": {},
   "source": [
    "## Function to compute LBP histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "bd25b5e6-a89f-4b75-8685-757fb8c95670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lbp_histogram(image, radius=1, n_points=8):\n",
    "    # Compute the LBP image using skimage's local_binary_pattern\n",
    "    lbp_image = local_binary_pattern(image, n_points, radius, method='uniform')\n",
    "    \n",
    "    # Compute the histogram of the LBP image\n",
    "    lbp_hist, _ = np.histogram(lbp_image.ravel(), bins=np.arange(0, 257), range=(0, 256))\n",
    "    \n",
    "    # Normalize the histogram\n",
    "    lbp_hist = lbp_hist.astype(float)\n",
    "    lbp_hist /= lbp_hist.sum()  # Normalize the histogram to make it a probability distribution\n",
    "    \n",
    "    return lbp_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abba462-0731-4cf5-8b51-d7a6de054e14",
   "metadata": {},
   "source": [
    "## Now apply LBP on each grayscale image to get the histograms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d019f2a3-8bf4-4ecb-986b-729c416b8d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3059, 256)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_lbp = np.array([compute_lbp_histogram(img) for img in X_train_gray])\n",
    "X_test_lbp = np.array([compute_lbp_histogram(img) for img in X_test_gray])\n",
    "X_train_lbp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e7bd0c03-c7ec-4f04-a3e8-4874c8face06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6085, 256)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_lbp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ab352-4e0e-45f2-8e78-8659975e0ac7",
   "metadata": {},
   "source": [
    "## Training the Kmean model on the Training set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "59a8aed4-cb53-4d10-a283-5c6d25860ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1-x2)**2))\n",
    "\n",
    "class KMeans:\n",
    "\n",
    "    def __init__(self, K=5, max_iters=100, plot_steps=False):\n",
    "        self.K = K\n",
    "        self.max_iters = max_iters\n",
    "        self.plot_steps = plot_steps\n",
    "\n",
    "        # list of sample indices for each cluster\n",
    "        self.clusters = [[] for _ in range(self.K)]\n",
    "\n",
    "        # the centers (mean vector) for each cluster\n",
    "        self.centroids = []\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.X = X\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "\n",
    "        # initialize centroids randomly\n",
    "        random_sample_idxs = np.random.choice(self.n_samples, self.K, replace=False)\n",
    "        self.centroids = [self.X[idx] for idx in random_sample_idxs]\n",
    "\n",
    "        # optimize clusters\n",
    "        for _ in range(self.max_iters):\n",
    "            # assign samples to closest centroids (create clusters)\n",
    "            self.clusters = self._create_clusters(self.centroids)\n",
    "\n",
    "            if self.plot_steps:\n",
    "                self.plot()\n",
    "\n",
    "            # calculate new centroids from the clusters\n",
    "            centroids_old = self.centroids\n",
    "            self.centroids = self._get_centroids(self.clusters)\n",
    "\n",
    "            if self._is_converged(centroids_old, self.centroids):\n",
    "                break\n",
    "\n",
    "            if self.plot_steps:\n",
    "                self.plot()\n",
    "\n",
    "        # classify samples as the index of their clusters\n",
    "        return self._get_cluster_labels(self.clusters)\n",
    "\n",
    "    def _get_cluster_labels(self, clusters):\n",
    "        labels = np.empty(self.n_samples)\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            for sample_idx in cluster:\n",
    "                labels[sample_idx] = cluster_idx\n",
    "        return labels\n",
    "\n",
    "    def _create_clusters(self, centroids):\n",
    "        clusters = [[] for _ in range(self.K)]\n",
    "        for idx, sample in enumerate(self.X):\n",
    "            centroid_idx = self._closest_centroid(sample, centroids)\n",
    "            clusters[centroid_idx].append(idx)\n",
    "        return clusters\n",
    "\n",
    "    def _closest_centroid(self, sample, centroids):\n",
    "        distances = [euclidean_distance(sample, point) for point in centroids]\n",
    "        closest_idx = np.argmin(distances)\n",
    "        return closest_idx\n",
    "\n",
    "    def _get_centroids(self, clusters):\n",
    "        centroids = np.zeros((self.K, self.n_features))\n",
    "        for cluster_idx, cluster in enumerate(clusters):\n",
    "            if len(cluster) == 0:\n",
    "                # handle empty clusters by reinitializing with a random point\n",
    "                centroids[cluster_idx] = self.X[np.random.choice(self.n_samples)]\n",
    "            else:\n",
    "                cluster_mean = np.mean(self.X[cluster], axis=0)\n",
    "                centroids[cluster_idx] = cluster_mean\n",
    "        return centroids\n",
    "\n",
    "    def _is_converged(self, centroids_old, centroids, tol=1e-4):\n",
    "        distances = [euclidean_distance(centroids_old[i], centroids[i]) for i in range(self.K)]\n",
    "        return sum(distances) < tol\n",
    "\n",
    "    def plot(self):\n",
    "        self.plot_clusters_2D()\n",
    "\n",
    "    def plot_clusters_2D(self):\n",
    "        pca = PCA(n_components=2)\n",
    "        reduced_data = pca.fit_transform(self.X)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        # Plot each cluster\n",
    "        for i, cluster in enumerate(self.clusters):\n",
    "            points = reduced_data[cluster]\n",
    "            ax.scatter(points[:, 0], points[:, 1], label=f\"Cluster {i}\")\n",
    "\n",
    "        # Plot the centroids (in the 2D PCA space)\n",
    "        centroids_2d = pca.transform(self.centroids)\n",
    "        ax.scatter(centroids_2d[:, 0], centroids_2d[:, 1], marker=\"x\", color=\"black\", linewidth=2, s=100)\n",
    "\n",
    "        ax.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2e418480-011e-4a32-ae5b-1587ef1d6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_lbp = np.vstack((X_train_lbp, X_test_lbp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ca229647-7609-4db9-ae03-26ca140e8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_y = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "27f6d30c-bdf2-49f5-8052-c3952dc421f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = len(np.unique(combined_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58863a6-9190-46f7-bdc3-346a7918f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = KMeans(K=clusters, max_iters=150, plot_steps=False)\n",
    "y_pred = k.predict(combined_lbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96aa02d-21d3-4249-96bd-7c53036eedeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_y = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca59906-d6b1-4701-9f5e-588a23bbfb72",
   "metadata": {},
   "source": [
    "## Evaluate the classifier's performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9672e7ab-c6f5-42dc-b54c-7d2450247930",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(combined_y.flatten(), y_kmeans)\n",
    "print(\"Accuracy: \", accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9463f-5107-4acd-92bb-6b77148d1d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
